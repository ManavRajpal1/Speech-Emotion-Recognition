{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ztf1osuw9D7",
        "outputId": "6ee47d89-2179-4e99-e779-c84d22388899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv1D, Concatenate, Dense, Multiply, Add, Reshape, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "SOlqNeBLxLI-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract MFCC features\n",
        "def extract_mfcc(audio_file, n_mfcc=26, hop_length=512, pad_length=300):\n",
        "    y, sr = librosa.load(audio_file, sr=None)  # Load audio file\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)  # Extract MFCC features\n",
        "    # Pad or truncate to a fixed length\n",
        "    if mfccs.shape[1] < pad_length:\n",
        "        mfccs = np.pad(mfccs, ((0, 0), (0, pad_length - mfccs.shape[1])), mode='constant')\n",
        "    else:\n",
        "        mfccs = mfccs[:, :pad_length]\n",
        "    return mfccs\n",
        "\n",
        "# Path to the RAVDESS dataset directory\n",
        "ravdess_dir = \"/content/drive/MyDrive/dataset/\"\n",
        "\n",
        "# Lists to hold the MFCCs and labels\n",
        "mfccs_data = []\n",
        "labels = []\n",
        "\n",
        "# Mapping for emotions\n",
        "emotion_map = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n",
        "\n",
        "# Emotions to include\n",
        "included_emotions = ['neutral', 'angry', 'sad', 'happy']\n",
        "\n",
        "# Iterate through each audio file in the dataset\n",
        "for actor_dir in os.listdir(ravdess_dir):\n",
        "    actor_subdir = os.path.join(ravdess_dir, actor_dir)\n",
        "    if os.path.isdir(actor_subdir):\n",
        "        for filename in os.listdir(actor_subdir):\n",
        "            if filename.endswith('.wav'):\n",
        "                emotion_code = filename.split('-')[2]\n",
        "                emotion = emotion_map[emotion_code]\n",
        "                if emotion in included_emotions:\n",
        "                    audio_file = os.path.join(actor_subdir, filename)\n",
        "                    mfccs = extract_mfcc(audio_file)\n",
        "                    mfccs_data.append(mfccs)\n",
        "                    labels.append(included_emotions.index(emotion))  # Using index as label\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "mfccs_data = np.array(mfccs_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print shape of the MFCCs and labels arrays\n",
        "print(\"MFCCs shape:\", mfccs_data.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gXyZfFOxQMq",
        "outputId": "bcaa654b-2e60-4e95-9283-eadec2c9c51f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCCs shape: (672, 26, 300)\n",
            "Labels shape: (672,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(mfccs_data, labels, test_size=0.4, random_state=0)\n",
        "# X_train=StandardScaler().fit_transform(X_train)"
      ],
      "metadata": {
        "id": "GpxOAKKfxVGd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "CwvuFFmpxY_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac7dc6a-a970-4607-9048-6522e632370f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (403, 26, 300)\n",
            "X_test shape: (269, 26, 300)\n",
            "y_train shape: (403,)\n",
            "y_test shape: (269,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train and y_test are already defined\n",
        "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "print(\"Unique values in y_train:\", unique_train)\n",
        "print(\"Counts in y_train:\", counts_train)\n",
        "\n",
        "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "print(\"Unique values in y_test:\", unique_test)\n",
        "print(\"Counts in y_test:\", counts_test)"
      ],
      "metadata": {
        "id": "5STYD1XUxbXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fea4bd6-3de5-4e01-8dbe-d15869a47ad4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_train: [0 1 2 3]\n",
            "Counts in y_train: [ 60 121 109 113]\n",
            "Unique values in y_test: [0 1 2 3]\n",
            "Counts in y_test: [36 71 83 79]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def mua_module(input_tensor):\n",
        "    # Weighting the Time Dimension\n",
        "    x_time = tf.transpose(input_tensor, perm=[0, 2, 3, 1])\n",
        "    x_time_gap = tf.reduce_mean(x_time, axis=[1, 2], keepdims=True)\n",
        "    x_time = Dense(4, activation='relu')(x_time_gap)\n",
        "    x_time = Dense(1, activation='relu')(x_time)\n",
        "    x_time = Reshape((1, 1, -1))(x_time)\n",
        "\n",
        "    # Weighting the Frequency Dimension\n",
        "    x_frequency = tf.transpose(input_tensor, perm=[0, 2, 3, 1])\n",
        "    x_frequency_gap = tf.reduce_mean(x_frequency, axis=[1, 2], keepdims=True)\n",
        "    x_frequency = Dense(2, activation='relu')(x_frequency_gap)\n",
        "    x_frequency = Dense(1, activation='relu')(x_frequency)\n",
        "    x_frequency = Reshape((1, 1, -1))(x_frequency)\n",
        "\n",
        "    # Weighting the Channel Dimension\n",
        "    x_channel_gap = tf.reduce_mean(input_tensor, axis=[1, 2], keepdims=True)\n",
        "    q = Conv2D(filters=input_tensor.shape[3], kernel_size=(3, 3), padding='same')(x_channel_gap)\n",
        "    k = Conv2D(filters=input_tensor.shape[3], kernel_size=(3, 3), padding='same')(x_channel_gap)\n",
        "    v = Conv2D(filters=input_tensor.shape[3], kernel_size=(3, 3), padding='same')(x_channel_gap)\n",
        "    h = tf.nn.softmax(q * k) * v\n",
        "\n",
        "    # Concatenate h along the channel axis\n",
        "    h_concat = Concatenate(axis=-1)([h, h, h])\n",
        "\n",
        "    w = Dense(input_tensor.shape[3], activation='tanh')(h_concat)\n",
        "    w = Reshape((1, 1, -1))(w)\n",
        "\n",
        "    # Apply attention weights to the input tensor\n",
        "    x_out = Multiply()([input_tensor, x_time])\n",
        "    x_out = Add()([x_out, Multiply()([input_tensor, x_frequency])])\n",
        "    x_out = Add()([x_out, Multiply()([input_tensor, w])])\n",
        "    return x_out\n",
        "def create_mlf_extractor_with_mua(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    conv_4x4 = Conv2D(filters=64, kernel_size=(4, 4), activation='relu', padding='same')(input_layer)\n",
        "    conv_4x4 = Conv2D(filters=32, kernel_size=(4, 4), activation='relu', padding='same')(conv_4x4)\n",
        "    conv_4x4 = Dropout(0.3)(conv_4x4)\n",
        "    conv_2x8 = Conv2D(filters=64, kernel_size=(2, 8), activation='relu', padding='same')(input_layer)\n",
        "    conv_2x8 = Conv2D(filters=32, kernel_size=(2, 8), activation='relu', padding='same')(conv_2x8)\n",
        "    conv_2x8 = Dropout(0.3)(conv_2x8)\n",
        "    conv_10x2 = Conv2D(filters=64, kernel_size=(10, 2), activation='relu', padding='same')(input_layer)\n",
        "    conv_10x2 = Conv2D(filters=32, kernel_size=(10, 2), activation='relu', padding='same')(conv_10x2)\n",
        "    conv_10x2= Dropout(0.3)(conv_10x2)\n",
        "    merged_layer = Concatenate()([conv_4x4, conv_2x8, conv_10x2])\n",
        "    mua_out = mua_module(merged_layer)\n",
        "    GlobalAvg_layer = GlobalAveragePooling2D()(mua_out)\n",
        "    dense_layer_1 = Dense(1024, activation='relu')(GlobalAvg_layer)\n",
        "    dense_layer_2 = Dense(1024, activation='relu')(dense_layer_1)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dense_layer_2)\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Rv0Bn60txd21"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_compile_model(input_shape, num_classes):\n",
        "    model = create_mlf_extractor_with_mua(input_shape, num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Adjust the learning rate\n",
        "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "num_classes = len(np.unique(y_train))\n",
        "input_shape = X_train[0].shape + (1,)\n",
        "model = create_compile_model(input_shape, num_classes)"
      ],
      "metadata": {
        "id": "_BGbAo0Qxirq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "eb2d005f-5e0c-4cde-b555-a7827902c985"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-25ac4d8eae95>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_compile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-25ac4d8eae95>\u001b[0m in \u001b[0;36mcreate_compile_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_compile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mlf_extractor_with_mua\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3d149a506934>\u001b[0m in \u001b[0;36mcreate_mlf_extractor_with_mua\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mconv_10x2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_10x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmerged_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_4x4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_2x8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_10x2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmua_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmua_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mGlobalAvg_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmua_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mdense_layer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalAvg_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3d149a506934>\u001b[0m in \u001b[0;36mmua_module\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmua_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Weighting the Time Dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mx_time_gap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_time_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "KnsDv3SiMII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_reshaped = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_reshaped = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "RPWEvHYxxlv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.expand_dims(y_train, axis=1)\n",
        "y_test = np.expand_dims(y_test, axis=1)"
      ],
      "metadata": {
        "id": "3BBH5NrixpOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape and number of classes\n",
        "input_shape = (26, 300, 1)  # Assuming input shape for MFCC features\n",
        "num_classes = 4  # Number of output classes\n",
        "\n",
        "# Create model\n",
        "model = create_mlf_extractor_with_mua(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Reshape the input data to include the channel dimension\n",
        "X_train_reshaped = X_train[..., np.newaxis]\n",
        "X_test_reshaped = X_test[..., np.newaxis]\n",
        "\n",
        "# # Reshape the labels to match the logits shape\n",
        "# y_train_reshaped = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test_reshaped = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define early stopping\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model using the reshaped input data\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped,y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test, batch_size=32)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "fC9rx0p9xsG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/dataset/\"\n",
        "model.save(save_directory + 'model.h5')\n",
        "\n",
        "# Optionally, you can load the model later using:\n",
        "# loaded_model = load_model(save_directory + 'model.h5')"
      ],
      "metadata": {
        "id": "UkLq9eDwO-rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Obtain predictions on test data\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Define labels for the confusion matrix\n",
        "emotion_labels = ['neutral', 'angry', 'sad', 'happy']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ccYJwqy8PNVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict for the test set\n",
        "y_pred=model.predict(X_test_reshaped)"
      ],
      "metadata": {
        "id": "1bbFLCM4RDkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mapping of emotion labels to their respective indices\n",
        "emotion_labels = ['neutral', 'angry', 'sad', 'happy']\n",
        "\n",
        "# Convert predicted probabilities to emotion labels\n",
        "predicted_emotions = [emotion_labels[np.argmax(prediction)] for prediction in y_pred]\n",
        "\n",
        "# Convert integer labels of y_test to emotion labels\n",
        "actual_emotions = [emotion_labels[label] for label in y_test]\n",
        "\n",
        "# Create a DataFrame to compare actual and predicted emotions\n",
        "df = pd.DataFrame({'Actual': actual_emotions, 'Predicted': predicted_emotions})\n",
        "\n",
        "# Print the first 20 rows of the DataFrame\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "gVvSH2zIREoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oKzcl2fS0yw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}